ğŸš€ Self-Managed Production-Style Kubernetes Cluster on AWS

Fully automated using Terraform, Ansible, and GitHub Actions

ğŸ“Œ Project Overview

This repository implements a self-managed, production-style Kubernetes cluster on AWS, fully automated from infrastructure provisioning to cluster bootstrap and clean teardown.

Unlike local Kubernetes tools or managed services, this project exposes real Kubernetes internals, real cloud networking, and real operational challenges â€” making it ideal for learning, experimentation, and platform engineering practice.

This is not a demo cluster.
It is a long-living, reusable Kubernetes environment designed to behave like production.

â“ Why This Project Exists
The Problem

Local tools (Minikube, Kind) do not reflect production reality

Managed Kubernetes (EKS) hides critical internals

Manual cluster creation is slow and inconsistent

Private networking, NAT, and security are hard to practice locally

Forgotten cloud resources lead to unexpected costs

The Goal

To create a repeatable, destroyable, cost-aware Kubernetes cluster that:

Runs in a real cloud

Uses private networking

Is fully automated

Can be reused for deep Kubernetes learning and experimentation

âœ… What This Project Solves

Provides a real AWS-based Kubernetes cluster

Uses private subnets with bastion-based access

Automates the entire lifecycle (create â†’ use â†’ destroy)

Separates infrastructure and configuration

Enables safe experimentation without manual setup

ğŸ§  Who Should Use This

Beginners â€” understand how Kubernetes is built in real environments

Engineers â€” learn Terraform, Ansible, and Kubernetes together

DevOps / Platform Engineers â€” practice production-style cluster design

MLOps / SRE learners â€” experiment with realistic infrastructure

ğŸ—ï¸ Architecture Overview
GitHub Actions (Self-Hosted Runner)
        |
        v
Terraform â†’ AWS Infrastructure
        |
        v
Bastion Host (Public Subnet)
        |
        v
Kubernetes Nodes (Private Subnets)

Key Design Principles

Kubernetes nodes have no public IPs

All access happens via a bastion host

Infrastructure and configuration are fully automated

The cluster can be safely destroyed anytime

ğŸŒ Networking & Security Model

Custom AWS VPC

Public Subnet

Bastion Host (single entry point)

Private Subnets

Kubernetes Control Plane

Worker Nodes

NAT Gateway for outbound access

Strict Security Group rules

This setup mirrors real production security boundaries.

ğŸ”„ How the System Works (Flow)

GitHub Actions orchestrates the workflow using a self-hosted runner

Terraform provisions all AWS infrastructure (VPC, EC2, networking)

Terraform outputs are used to generate a dynamic Ansible inventory

Ansible, executed via the bastion, configures:

OS prerequisites

containerd runtime

Kubernetes components via kubeadm

The Kubernetes cluster is initialized and validated

kubeconfig is securely retrieved for cluster access

The cluster can be destroyed cleanly using Terraform

Everything is automated â€” no manual SSH hopping, no hardcoded values.

ğŸ§° Tools & Technologies Used
Infrastructure

AWS EC2 â€“ Compute

AWS VPC â€“ Networking

NAT & Internet Gateway â€“ Controlled internet access

Security Groups â€“ Firewall rules

Automation

Terraform â€“ Infrastructure provisioning

Ansible â€“ OS & Kubernetes configuration

GitHub Actions â€“ CI/CD orchestration

Self-Hosted Runner â€“ Secure execution environment

Kubernetes Stack

kubeadm â€“ Cluster initialization

kubelet â€“ Node agent

kubectl â€“ Cluster management

containerd â€“ Container runtime

Calico â€“ CNI networking

ğŸ“‚ Repository Structure
.github/workflows/
  create-cluster.yml
  destroy-cluster.yml

terraform/
  main.tf
  variables.tf
  outputs.tf
  providers.tf
  versions.tf

ansible/
  inventory/
    inventory.ini.j2
  playbooks/
    bastion.yml
    bootstrap.yml
    control-plane.yml
    workers.yml
    network.yml
    kubeconfig.yml
    validate.yml

scripts/
  generate-inventory.sh
  generate-kubeconfig.sh
  wait-for-ssh.sh

ğŸ¯ What You Achieve With This Project

Hands-on experience with real Kubernetes internals

Practice production-grade networking and security

Learn end-to-end automation

Experiment safely with:

Storage (PV / PVC)

Networking & ingress

Node failures and recovery

MLOps and SRE workflows

Avoid cloud cost surprises through clean teardown

ğŸ”® Future Enhancements

Multi-control-plane (HA) setup

API server load balancer

Ingress controller

Monitoring & logging stack

Autoscaling

GPU-enabled node pools

Policy enforcement (OPA / Kyverno)

â­ Why This Project Matters

This repository demonstrates:

Infrastructure-as-Code discipline

Secure production-style networking

Real Kubernetes bootstrapping

Automation-first design

Cost-aware cloud usage

It is built to be read, reused, extended, broken, and fixed â€” just like real production systems.
